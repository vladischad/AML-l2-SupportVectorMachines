{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33837e32",
   "metadata": {},
   "source": [
    "# CS334 Lab2: Support Vector Machines\n",
    "\n",
    "**Total:** 100 points  \n",
    "\n",
    "This lab covers the core ideas from the SVM chapter: large margin intuition, feature scaling, soft-margin (C), kernels (RBF γ), and when to choose `LinearSVC` vs `SVC` vs `SGDClassifier`.\n",
    "\n",
    "## Learning goals\n",
    "- Train a linear SVM with proper scaling and interpret the `decision_function()` score.\n",
    "- See how **C** and **γ (gamma)** control the flexibility of an RBF-kernel SVM.\n",
    "- Compare `LinearSVC`, `SVC`, and `SGDClassifier` in practice and connect results to time complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8acb69",
   "metadata": {},
   "source": [
    "## Setup.\n",
    "Run the cell below once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1015a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris, make_moons, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Helper function to plot decision regions\n",
    "def plot_decision_regions(clf, X, y, title=None, ax=None, h=0.02):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n",
    "    y_min, y_max = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = clf.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.25)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fccf8e",
   "metadata": {},
   "source": [
    "## Task 1 — Linear SVM + scaling + confidence scores (30 pts)\n",
    "**Goal:** Train a linear SVM to detect *Iris virginica* using petal length/width.\n",
    "\n",
    "Steps:\n",
    "1. Load iris. Use only the 2 features: **petal length** and **petal width**.\n",
    "2. Split into train/test (80/20), with random_state=42 and stratify=y.\n",
    "3. [10 pts] Build a pipeline: `StandardScaler()` → `LinearSVC(C=1)`. Train the pipeline and print train/test accuracy.\n",
    "4. [10 pts] Compute `decision_function()` for the two points: `[[5.5, 1.7], [5.0, 1.5]]`, and print the results.\n",
    "5. [10 pts] Explain what the sign and magnitude of `decision_function()` mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098fa4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.95\n",
      "\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "decision_function: [ 0.55042329 -0.22312592]\n"
     ]
    }
   ],
   "source": [
    "# Load iris data and use two features [\"petal length (cm)\", \"petal width (cm)\"]\n",
    "# and only use the last two classes (1 and 2)\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 2)  # 1 = virginica, 0 = not virginica\n",
    "\n",
    "# Split into train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Your code: Build a pipeline: StandardScaler() -> LinearSVC(C=1)\n",
    "clf = make_pipeline(StandardScaler(), LinearSVC(C=1, random_state=42))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Your code: Train the pipeline, report train/test accuracy.\n",
    "print(\"Train accuracy:\", clf.score(X_train, y_train))\n",
    "print(\"\\nTest accuracy:\", clf.score(X_test, y_test))\n",
    "\n",
    "# Your code: Compute decision_function() for the two points: [[5.5, 1.7], [5.0, 1.5]]\n",
    "pts = np.array([[5.5, 1.7], [5.0, 1.5]])\n",
    "print(\"\\ndecision_function:\", clf.decision_function(pts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fa0ae",
   "metadata": {},
   "source": [
    "Your answer to 5:\n",
    "\n",
    "Sign: positive predicts virginica (1), negative predicts not virginica (0).\n",
    "\n",
    "Magnitude: value is proportional to distance from the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d61ae",
   "metadata": {},
   "source": [
    "## Task 2 — RBF kernel: tuning **γ (gamma)** and **C** (30 pts)\n",
    "**Goal:** See underfitting vs overfitting by sweeping γ and C.\n",
    "\n",
    "Steps:\n",
    "1. (code provided) Use moons data, and split train/test.\n",
    "2. [10 pts] Train `SVC(kernel='rbf')` on a small grid:\n",
    "   - `gamma` in `{0.1, 1, 10}`\n",
    "   - `C` in `{0.1, 1, 100}`\n",
    "3. [10 pts] For each combo, report train accuracy and test accuracy. Use pandas to display results in a table (sorted by gamma and C).\n",
    "4. [10 pts] Pick one underfitting and one overfitting setting and explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c06ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.821333</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.885333</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma      C  train_acc  test_acc\n",
       "0    0.1    0.1   0.821333     0.832\n",
       "1    0.1    1.0   0.848000     0.832\n",
       "2    0.1  100.0   0.901333     0.904\n",
       "3    1.0    0.1   0.885333     0.880\n",
       "4    1.0    1.0   0.922667     0.928\n",
       "5    1.0  100.0   0.936000     0.912\n",
       "6   10.0    0.1   0.933333     0.912\n",
       "7   10.0    1.0   0.938667     0.912\n",
       "8   10.0  100.0   0.954667     0.888"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "gammas = [0.1, 1, 10]\n",
    "Cs = [0.1, 1, 100]\n",
    "\n",
    "# Your code: train SVC with rbf kernel on a small grid\n",
    "results = []\n",
    "\n",
    "for g in gammas:\n",
    "    for C in Cs:\n",
    "        clf = SVC(kernel=\"rbf\", gamma=g, C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        results.append({\n",
    "            \"gamma\": g,\n",
    "            \"C\": C,\n",
    "            \"train_acc\": clf.score(X_train, y_train),\n",
    "            \"test_acc\": clf.score(X_test, y_test),\n",
    "        })\n",
    "\n",
    "# Your code: for each combo, report train accuracy and test accuracy\n",
    "df = pd.DataFrame(results).sort_values([\"gamma\", \"C\"]).reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84edc7f",
   "metadata": {},
   "source": [
    "Your answer to 4:\n",
    "\n",
    "Underfitting: gamma 0.1, C 0.1 (both train and test are relatively low which means that model is too simple/too much regularization).\n",
    "\n",
    "Overfitting: gamma 10, C 100 (train is highest but test drops a lot which means that model fits noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796bd85",
   "metadata": {},
   "source": [
    "## Task 3 — Choosing `LinearSVC` vs `SVC` vs `SGDClassifier` (40 pts)\n",
    "**Goal:** Compare accuracy and training time, then connect to computational complexity.\n",
    "\n",
    "Steps:\n",
    "1. Create a linearly separable dataset with *many* points: e.g.\n",
    "   `make_classification(n_samples=8000, n_features=20, n_informative=10, class_sep=1.5, random_state=42)`.\n",
    "2. [10 pts] Train these three models (each with scaling):\n",
    "   - `LinearSVC(C=1)`\n",
    "   - `SVC(kernel='linear', C=1)`\n",
    "   - `SVC(kernel='rbf', C=1)`\n",
    "   - `SGDClassifier(loss='hinge', alpha=1e-4)`\n",
    "3. [10 pts] Measure training time and test accuracy. Save in a dataframe (3 columns: model, train_time_sec, test_acc), display the dataframe.\n",
    "4. [20 pts] Briefly justify which model you’d choose for:\n",
    "   - (a) huge dataset (millions of rows)\n",
    "   - (b) small/medium dataset but potentially nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811ae532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     model  train_time_sec  test_acc\n",
      "0                           LinearSVC(C=1)        0.018825    0.9135\n",
      "1  SGDClassifier(loss='hinge', alpha=1e-4)        0.033017    0.8930\n",
      "2                   SVC(kernel='rbf', C=1)        0.385192    0.9770\n",
      "3                SVC(kernel='linear', C=1)        0.948611    0.9130\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=8000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=2,\n",
    "    class_sep=1.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "def fit_time_and_acc(model, X_train, y_train, X_test, y_test):\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time.perf_counter()\n",
    "    acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    return (t1 - t0), acc\n",
    "\n",
    "# Your code: train models (each with scaling)\n",
    "models = {\n",
    "    \"LinearSVC(C=1)\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearSVC(C=1, random_state=42, dual=\"auto\")\n",
    "    ),\n",
    "    \"SVC(kernel='linear', C=1)\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel=\"linear\", C=1)\n",
    "    ),\n",
    "    \"SVC(kernel='rbf', C=1)\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel=\"rbf\", C=1, gamma=\"scale\")\n",
    "    ),\n",
    "    \"SGDClassifier(loss='hinge', alpha=1e-4)\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SGDClassifier(loss=\"hinge\", alpha=1e-4, random_state=42)\n",
    "    )\n",
    "}\n",
    "\n",
    "# Your code: Measure training time and test accuracy for each model, save in a dataframe (3 columns: model, train_time_sec, test_acc), display the dataframe.\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    train_time, test_acc = fit_time_and_acc(model, X_train, y_train, X_test, y_test)\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"train_time_sec\": train_time,\n",
    "        \"test_acc\": test_acc\n",
    "    })\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(rows).sort_values(\"train_time_sec\").reset_index(drop=True)\n",
    "\n",
    "# Display results\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb0e8a",
   "metadata": {},
   "source": [
    "Your answer to 4:\n",
    "\n",
    "(a) Huge dataset: SGDClassifier (or LinearSVC) — scales well, fast training.\n",
    "\n",
    "(b) Small/medium nonlinear: SVC with RBF kernel — captures nonlinear patterns, higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec21ea2-1f01-436e-8317-348749d70fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
